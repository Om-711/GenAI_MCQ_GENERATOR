{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eb6a80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe54f766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: PyPDF2 in c:\\users\\om chiddarwar\\appdata\\roaming\\python\\python312\\site-packages (3.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e05adaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f433afe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langchain\n",
      "  Using cached langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain)\n",
      "  Using cached langchain_core-0.3.72-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.9-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith>=0.1.17 (from langchain)\n",
      "  Using cached langsmith-0.4.8-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (2.0.34)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.2.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.11.0)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (24.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.27.0)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith>=0.1.17->langchain)\n",
      "  Using cached orjson-3.11.1-cp312-cp312-win_amd64.whl.metadata (43 kB)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: anyio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\programdata\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (2.1)\n",
      "Using cached langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "Using cached langchain_core-0.3.72-py3-none-any.whl (442 kB)\n",
      "Using cached langchain_text_splitters-0.3.9-py3-none-any.whl (33 kB)\n",
      "Using cached langsmith-0.4.8-py3-none-any.whl (367 kB)\n",
      "Using cached orjson-3.11.1-cp312-cp312-win_amd64.whl (131 kB)\n",
      "Installing collected packages: orjson, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "Successfully installed langchain-0.3.27 langchain-core-0.3.72 langchain-text-splitters-0.3.9 langsmith-0.4.8 orjson-3.11.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88180fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "import re\n",
    "\n",
    "class GeminiTokenUsageSimulator(BaseCallbackHandler):\n",
    "    def __init__(self):\n",
    "        self.prompt_tokens = 0\n",
    "        self.completion_tokens = 0\n",
    "        self.total_tokens = 0\n",
    "\n",
    "    def on_llm_start(self, serialized, prompts, **kwargs):\n",
    "        self.prompt_tokens = sum(self.estimate_tokens(prompt) for prompt in prompts)\n",
    "\n",
    "    def on_llm_end(self, response, **kwargs):\n",
    "        output = response.generations[0][0].text\n",
    "        self.completion_tokens = self.estimate_tokens(output)\n",
    "        self.total_tokens = self.prompt_tokens + self.completion_tokens\n",
    "        print(f\"\\nðŸ”¹ Prompt tokens: {self.prompt_tokens}\")\n",
    "        print(f\"ðŸ”¹ Completion tokens: {self.completion_tokens}\")\n",
    "        print(f\"ðŸ”¹ Total tokens: {self.total_tokens}\")\n",
    "\n",
    "    def estimate_tokens(self, text):\n",
    "        return len(re.findall(r'\\w+', text))  # Simple estimation: count words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1484042e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langchain-google-genai\n",
      "  Using cached langchain_google_genai-2.1.8-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n",
      "  Using cached google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.68 in c:\\users\\om chiddarwar\\appdata\\roaming\\python\\python312\\site-packages (from langchain-google-genai) (0.3.72)\n",
      "Requirement already satisfied: pydantic<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-google-genai) (2.8.2)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai)\n",
      "  Using cached google_api_core-2.25.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai)\n",
      "  Using cached google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting proto-plus<2.0.0,>=1.22.3 (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai)\n",
      "  Using cached proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.25.3)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\om chiddarwar\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.4.8)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (8.2.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (4.11.0)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (24.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<3,>=2->langchain-google-genai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<3,>=2->langchain-google-genai) (2.20.1)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai)\n",
      "  Using cached googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.32.3)\n",
      "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai)\n",
      "  Downloading grpcio-1.74.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai)\n",
      "  Using cached grpcio_status-1.74.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai)\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (2.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\om chiddarwar\\appdata\\roaming\\python\\python312\\site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (3.11.1)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.23.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai)\n",
      "  Using cached protobuf-6.31.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: anyio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\programdata\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.14.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.2.3)\n",
      "Using cached langchain_google_genai-2.1.8-py3-none-any.whl (47 kB)\n",
      "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Using cached google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
      "Using cached google_api_core-2.25.1-py3-none-any.whl (160 kB)\n",
      "Using cached google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
      "Using cached proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading grpcio-1.74.0-cp312-cp312-win_amd64.whl (4.5 MB)\n",
      "   ---------------------------------------- 0.0/4.5 MB ? eta -:--:--\n",
      "   ---------------------------- ----------- 3.1/4.5 MB 23.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.5/4.5 MB 24.6 MB/s eta 0:00:00\n",
      "Downloading grpcio_status-1.74.0-py3-none-any.whl (14 kB)\n",
      "Using cached protobuf-6.31.1-cp310-abi3-win_amd64.whl (435 kB)\n",
      "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Installing collected packages: filetype, rsa, protobuf, grpcio, proto-plus, googleapis-common-protos, google-auth, grpcio-status, google-api-core, google-ai-generativelanguage, langchain-google-genai\n",
      "Successfully installed filetype-1.2.0 google-ai-generativelanguage-0.6.18 google-api-core-2.25.1 google-auth-2.40.3 googleapis-common-protos-1.70.0 grpcio-1.74.0 grpcio-status-1.74.0 langchain-google-genai-2.1.8 proto-plus-1.26.1 protobuf-6.31.1 rsa-4.9.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script filetype.exe is installed in 'C:\\Users\\OM CHIDDARWAR\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts pyrsa-decrypt.exe, pyrsa-encrypt.exe, pyrsa-keygen.exe, pyrsa-priv2pub.exe, pyrsa-sign.exe and pyrsa-verify.exe are installed in 'C:\\Users\\OM CHIDDARWAR\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.37.1 requires protobuf<6,>=3.20, but you have protobuf 6.31.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-google-genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "540bb534",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "token_logger = GeminiTokenUsageSimulator()\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0.7\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f77c52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8eef5fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f907699",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = \"\"\"\n",
    "text : {text}\n",
    "You are an expert in making quizzes.Given the text above, generate a quiz with {number} questions on the topic of {subject}.\n",
    "The quiz should be in the {tone} tone.Make Sure questions should not be repeated.Make sure to format your response your format like RESPONSE_JSON below and use\n",
    "it as a guide.\n",
    "Ensure to make {number} MCQs\n",
    "### RESPONSE_JSON\n",
    "{response_json}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "655baaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_json = {\n",
    "    \"1\":{\n",
    "        \"mcq\" : \"Multiple Choice Question \",\n",
    "        \"options\" : [\n",
    "            \"Option A\",\n",
    "            \"Option B\",\n",
    "            \"Option C\",\n",
    "            \"Option D\"\n",
    "        ],\n",
    "        \"answer\" : \"correct answer\"\n",
    "    },\n",
    "    \"2\":{\n",
    "        \"mcq\" : \"Multiple Choice Question 2\",\n",
    "        \"options\" : [\n",
    "            \"Option A\",\n",
    "            \"Option B\",\n",
    "            \"Option C\",\n",
    "            \"Option D\"\n",
    "        ],\n",
    "        \"answer\" : \"correct answer\"\n",
    "    },\n",
    "    \"3\":{\n",
    "        \"mcq\" : \"Multiple Choice Question 3\",\n",
    "        \"options\" : [\n",
    "            \"Option A\",\n",
    "            \"Option B\",\n",
    "            \"Option C\",\n",
    "            \"Option D\"\n",
    "        ],\n",
    "        \"answer\" : \"correct answer\"\n",
    "    },\n",
    "    \"4\":{\n",
    "        \"mcq\" : \"Multiple Choice Question 4\",\n",
    "        \"options\" : [\n",
    "            \"Option A\",\n",
    "            \"Option B\",\n",
    "            \"Option C\",\n",
    "            \"Option D\"\n",
    "        ],\n",
    "        \"answer\" : \"correct answer\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "25ab5c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "    template = TEMPLATE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0cc9278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_chain = LLMChain(llm=llm, prompt=quiz_generation_prompt, output_key=\"quiz\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5c24b7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE2 = \"\"\"\n",
    "You are an expert in english grammarian and writer. Given a Multiple Choice Quiz (MCQ) for {subject} students.You need to\n",
    "evaluare the quiz  question complexeity and give a complete analysis of the quiz.Only use atmost 30 words to describe the complexeity of quiz\n",
    "update the quiz question which needs to be change the tone such that it perfectly fits the statement abilities\n",
    "Quiz MCQs {quiz}. \n",
    "\n",
    "Check from an expert of the above quiz\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "270960f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_evaluation_prompt = PromptTemplate(\n",
    "    input_variables=[\"quiz\", \"subject\"],\n",
    "    template=TEMPLATE2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9f55b4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_eval = LLMChain(llm=llm, prompt=quiz_evaluation_prompt, output_key=\"review\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6df49f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['number', 'response_json', 'subject', 'text', 'tone']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiz_chain.prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "56dcbd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verbose=True prompt=PromptTemplate(input_variables=['number', 'response_json', 'subject', 'text', 'tone'], input_types={}, partial_variables={}, template='\\ntext : {text}\\nYou are an expert in making quizzes.Given the text above, generate a quiz with {number} questions on the topic of {subject}.\\nThe quiz should be in the {tone} tone.Make Sure questions should not be repeated.Make sure to format your response your format like RESPONSE_JSON below and use\\nit as a guide.\\nEnsure to make {number} MCQs\\n### RESPONSE_JSON\\n{response_json}\\n') llm=ChatGoogleGenerativeAI(model='models/gemini-2.5-flash', google_api_key=SecretStr('**********'), client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x00000173CE3B0560>, default_metadata=(), model_kwargs={}) output_key='quiz' output_parser=StrOutputParser() llm_kwargs={}\n"
     ]
    }
   ],
   "source": [
    "print(quiz_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e59221e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_eval_chain = SequentialChain(chains=[quiz_chain, quiz_eval], input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "                                      output_variables=[\"quiz\", \"review\"],\n",
    "                                      verbose=True)\n",
    "                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6247fbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\G'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\G'\n",
      "C:\\Users\\OM CHIDDARWAR\\AppData\\Local\\Temp\\ipykernel_6984\\1520164779.py:1: SyntaxWarning: invalid escape sequence '\\G'\n",
      "  file_path = \"E:\\GenAI\\MCQ_GENERATOR\\data.txt\"\n"
     ]
    }
   ],
   "source": [
    "file_path = \"E:\\GenAI\\MCQ_GENERATOR\\data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6dfdb824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\GenAI\\\\MCQ_GENERATOR\\\\data.txt'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "110e4354",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, 'r') as file:\n",
    "    text = file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "32438ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In machine learning, deep learning focuses on utilizing multilayered neural networks to perform tasks such as classification, regression, and representation learning. The field takes inspiration from biological neuroscience and is centered around stacking artificial neurons into layers and \"training\" them to process data. The adjective \"deep\" refers to the use of multiple layers (ranging from three to several hundred or thousands) in the network. Methods used can be supervised, semi-supervised or unsupervised.[2]\n",
      "\n",
      "Some common deep learning network architectures include fully connected networks, deep belief networks, recurrent neural networks, convolutional neural networks, generative adversarial networks, transformers, and neural radiance fields. These architectures have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.[3][4][5]\n",
      "\n",
      "Early forms of neural networks were inspired by information processing and distributed communication nodes in biological systems, particularly the human brain. However, current neural networks do not intend to model the brain function of organisms, and are generally seen as low-quality models for that purpose.[6]\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0364c5ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"1\": {\"mcq\": \"Multiple Choice Question \", \"options\": [\"Option A\", \"Option B\", \"Option C\", \"Option D\"], \"answer\": \"correct answer\"}, \"2\": {\"mcq\": \"Multiple Choice Question 2\", \"options\": [\"Option A\", \"Option B\", \"Option C\", \"Option D\"], \"answer\": \"correct answer\"}, \"3\": {\"mcq\": \"Multiple Choice Question 3\", \"options\": [\"Option A\", \"Option B\", \"Option C\", \"Option D\"], \"answer\": \"correct answer\"}, \"4\": {\"mcq\": \"Multiple Choice Question 4\", \"options\": [\"Option A\", \"Option B\", \"Option C\", \"Option D\"], \"answer\": \"correct answer\"}}'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(response_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "80af71ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "text : In machine learning, deep learning focuses on utilizing multilayered neural networks to perform tasks such as classification, regression, and representation learning. The field takes inspiration from biological neuroscience and is centered around stacking artificial neurons into layers and \"training\" them to process data. The adjective \"deep\" refers to the use of multiple layers (ranging from three to several hundred or thousands) in the network. Methods used can be supervised, semi-supervised or unsupervised.[2]\n",
      "\n",
      "Some common deep learning network architectures include fully connected networks, deep belief networks, recurrent neural networks, convolutional neural networks, generative adversarial networks, transformers, and neural radiance fields. These architectures have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.[3][4][5]\n",
      "\n",
      "Early forms of neural networks were inspired by information processing and distributed communication nodes in biological systems, particularly the human brain. However, current neural networks do not intend to model the brain function of organisms, and are generally seen as low-quality models for that purpose.[6]\n",
      "You are an expert in making quizzes.Given the text above, generate a quiz with 5 questions on the topic of Deep learning.\n",
      "The quiz should be in the simple tone.Make Sure questions should not be repeated.Make sure to format your response your format like RESPONSE_JSON below and use\n",
      "it as a guide.\n",
      "Ensure to make 5 MCQs\n",
      "### RESPONSE_JSON\n",
      "{\n",
      "    \"1\": {\n",
      "        \"mcq\": \"Multiple Choice Question \",\n",
      "        \"options\": [\n",
      "            \"Option A\",\n",
      "            \"Option B\",\n",
      "            \"Option C\",\n",
      "            \"Option D\"\n",
      "        ],\n",
      "        \"answer\": \"correct answer\"\n",
      "    },\n",
      "    \"2\": {\n",
      "        \"mcq\": \"Multiple Choice Question 2\",\n",
      "        \"options\": [\n",
      "            \"Option A\",\n",
      "            \"Option B\",\n",
      "            \"Option C\",\n",
      "            \"Option D\"\n",
      "        ],\n",
      "        \"answer\": \"correct answer\"\n",
      "    },\n",
      "    \"3\": {\n",
      "        \"mcq\": \"Multiple Choice Question 3\",\n",
      "        \"options\": [\n",
      "            \"Option A\",\n",
      "            \"Option B\",\n",
      "            \"Option C\",\n",
      "            \"Option D\"\n",
      "        ],\n",
      "        \"answer\": \"correct answer\"\n",
      "    },\n",
      "    \"4\": {\n",
      "        \"mcq\": \"Multiple Choice Question 4\",\n",
      "        \"options\": [\n",
      "            \"Option A\",\n",
      "            \"Option B\",\n",
      "            \"Option C\",\n",
      "            \"Option D\"\n",
      "        ],\n",
      "        \"answer\": \"correct answer\"\n",
      "    }\n",
      "}\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert in english grammarian and writer. Given a Multiple Choice Quiz (MCQ) for Deep learning students.You need to\n",
      "evaluare the quiz  question complexeity and give a complete analysis of the quiz.Only use atmost 30 words to describe the complexeity of quiz\n",
      "update the quiz question which needs to be change the tone such that it perfectly fits the statement abilities\n",
      "Quiz MCQs ```json\n",
      "{\n",
      "    \"1\": {\n",
      "        \"mcq\": \"What does the word 'deep' refer to in deep learning?\",\n",
      "        \"options\": [\n",
      "            \"The deep understanding required by users\",\n",
      "            \"The use of multiple layers in the network\",\n",
      "            \"The complex problems it solves\",\n",
      "            \"The deep research involved in its creation\"\n",
      "        ],\n",
      "        \"answer\": \"The use of multiple layers in the network\"\n",
      "    },\n",
      "    \"2\": {\n",
      "        \"mcq\": \"Which of these is a common task that deep learning can perform?\",\n",
      "        \"options\": [\n",
      "            \"Building a physical robot\",\n",
      "            \"Cooking a gourmet meal\",\n",
      "            \"Classification\",\n",
      "            \"Writing a novel from scratch\"\n",
      "        ],\n",
      "        \"answer\": \"Classification\"\n",
      "    },\n",
      "    \"3\": {\n",
      "        \"mcq\": \"Deep learning methods can be categorized as which of the following?\",\n",
      "        \"options\": [\n",
      "            \"Only supervised\",\n",
      "            \"Only unsupervised\",\n",
      "            \"Supervised, semi-supervised, or unsupervised\",\n",
      "            \"Only semi-supervised\"\n",
      "        ],\n",
      "        \"answer\": \"Supervised, semi-supervised, or unsupervised\"\n",
      "    },\n",
      "    \"4\": {\n",
      "        \"mcq\": \"In which field has deep learning been applied, as mentioned in the text?\",\n",
      "        \"options\": [\n",
      "            \"Archaeology\",\n",
      "            \"Computer vision\",\n",
      "            \"Astronomy\",\n",
      "            \"Geology\"\n",
      "        ],\n",
      "        \"answer\": \"Computer vision\"\n",
      "    },\n",
      "    \"5\": {\n",
      "        \"mcq\": \"What is the current relationship between neural networks and modeling the human brain?\",\n",
      "        \"options\": [\n",
      "            \"They are perfect models of brain function.\",\n",
      "            \"They are designed to exactly replicate brain processes.\",\n",
      "            \"They do not intend to model the brain function of organisms.\",\n",
      "            \"They are primarily used to study the human brain.\"\n",
      "        ],\n",
      "        \"answer\": \"They do not intend to model the brain function of organisms.\"\n",
      "    }\n",
      "}\n",
      "```. \n",
      "\n",
      "Check from an expert of the above quiz\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = generate_eval_chain.invoke({\n",
    "    \"text\": text,\n",
    "    \"number\":5,\n",
    "    \"subject\": \"Deep learning\",\n",
    "    \"tone\":\"simple\",\n",
    "    \"response_json\":json.dumps(response_json, indent=4)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "abc48702",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz = response.get(\"quiz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a64cfc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"1\": {\n",
      "        \"mcq\": \"What does the word 'deep' refer to in deep learning?\",\n",
      "        \"options\": [\n",
      "            \"The deep understanding required by users\",\n",
      "            \"The use of multiple layers in the network\",\n",
      "            \"The complex problems it solves\",\n",
      "            \"The deep research involved in its creation\"\n",
      "        ],\n",
      "        \"answer\": \"The use of multiple layers in the network\"\n",
      "    },\n",
      "    \"2\": {\n",
      "        \"mcq\": \"Which of these is a common task that deep learning can perform?\",\n",
      "        \"options\": [\n",
      "            \"Building a physical robot\",\n",
      "            \"Cooking a gourmet meal\",\n",
      "            \"Classification\",\n",
      "            \"Writing a novel from scratch\"\n",
      "        ],\n",
      "        \"answer\": \"Classification\"\n",
      "    },\n",
      "    \"3\": {\n",
      "        \"mcq\": \"Deep learning methods can be categorized as which of the following?\",\n",
      "        \"options\": [\n",
      "            \"Only supervised\",\n",
      "            \"Only unsupervised\",\n",
      "            \"Supervised, semi-supervised, or unsupervised\",\n",
      "            \"Only semi-supervised\"\n",
      "        ],\n",
      "        \"answer\": \"Supervised, semi-supervised, or unsupervised\"\n",
      "    },\n",
      "    \"4\": {\n",
      "        \"mcq\": \"In which field has deep learning been applied, as mentioned in the text?\",\n",
      "        \"options\": [\n",
      "            \"Archaeology\",\n",
      "            \"Computer vision\",\n",
      "            \"Astronomy\",\n",
      "            \"Geology\"\n",
      "        ],\n",
      "        \"answer\": \"Computer vision\"\n",
      "    },\n",
      "    \"5\": {\n",
      "        \"mcq\": \"What is the current relationship between neural networks and modeling the human brain?\",\n",
      "        \"options\": [\n",
      "            \"They are perfect models of brain function.\",\n",
      "            \"They are designed to exactly replicate brain processes.\",\n",
      "            \"They do not intend to model the brain function of organisms.\",\n",
      "            \"They are primarily used to study the human brain.\"\n",
      "        ],\n",
      "        \"answer\": \"They do not intend to model the brain function of organisms.\"\n",
      "    }\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(quiz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e74edb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'str'>\n",
      "Length: 1879\n",
      "Content Preview: '```json\\n{\\n    \"1\": {\\n        \"mcq\": \"What does the word \\'deep\\' refer to in deep learning?\",\\n        \"options\": [\\n            \"The deep understanding required by users\",\\n            \"The use of multipl'\n"
     ]
    }
   ],
   "source": [
    "print(\"Type:\", type(quiz))\n",
    "print(\"Length:\", len(quiz))\n",
    "print(\"Content Preview:\", repr(quiz[:200]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3811fcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " JSON parsed successfully!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "cleaned_quiz = quiz.strip().removeprefix(\"```json\").removesuffix(\"```\").strip()\n",
    "\n",
    "try:\n",
    "    quiz_dict = json.loads(cleaned_quiz)\n",
    "    print(\" JSON parsed successfully!\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(\" JSON parsing failed:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "07440cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_table_data = []\n",
    "\n",
    "for key, value in quiz_dict.items():\n",
    "    mcq = value[\"mcq\"]\n",
    "    options = \" | \".join([f\"{i+1}: {opt}\" for i, opt in enumerate(value[\"options\"])])\n",
    "    correct = value.get(\"answer\", \"N/A\")\n",
    "\n",
    "    quiz_table_data.append({\n",
    "        \"MCQ\": mcq,\n",
    "        \"Choices\": options,\n",
    "        \"Correct\": correct\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e83a8c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'MCQ': \"What does the word 'deep' refer to in deep learning?\",\n",
       "  'Choices': '1: The deep understanding required by users | 2: The use of multiple layers in the network | 3: The complex problems it solves | 4: The deep research involved in its creation',\n",
       "  'Correct': 'The use of multiple layers in the network'},\n",
       " {'MCQ': 'Which of these is a common task that deep learning can perform?',\n",
       "  'Choices': '1: Building a physical robot | 2: Cooking a gourmet meal | 3: Classification | 4: Writing a novel from scratch',\n",
       "  'Correct': 'Classification'},\n",
       " {'MCQ': 'Deep learning methods can be categorized as which of the following?',\n",
       "  'Choices': '1: Only supervised | 2: Only unsupervised | 3: Supervised, semi-supervised, or unsupervised | 4: Only semi-supervised',\n",
       "  'Correct': 'Supervised, semi-supervised, or unsupervised'},\n",
       " {'MCQ': 'In which field has deep learning been applied, as mentioned in the text?',\n",
       "  'Choices': '1: Archaeology | 2: Computer vision | 3: Astronomy | 4: Geology',\n",
       "  'Correct': 'Computer vision'},\n",
       " {'MCQ': 'What is the current relationship between neural networks and modeling the human brain?',\n",
       "  'Choices': '1: They are perfect models of brain function. | 2: They are designed to exactly replicate brain processes. | 3: They do not intend to model the brain function of organisms. | 4: They are primarily used to study the human brain.',\n",
       "  'Correct': 'They do not intend to model the brain function of organisms.'}]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiz_table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "467e2065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'30-07-2025__16:53:49'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "datetime.now().strftime(\"%d-%m-%Y__%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352fd685",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
